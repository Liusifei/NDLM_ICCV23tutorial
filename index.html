<!DOCTYPE html>
<html lang="en">
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript"
    src="http://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
  </script>
    <head>
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <meta charset="utf-8">
        <title>NDLM2023</title>
        <link rel="stylesheet" href="style.css">
    </head>
    <body>
        <div class="nav">
            <div class="nav-container">
                <a href="index.html#">Home</a>
                <a href="index.html#intro">Overview</a>
                <a href="index.html#schedule">Schedule</a>
                <a href="index.html#speakers">Speakers</a>
                <a href="index.html#contact">Contact</a>
            </div>
        </div>

        <div class="title-container">
            <div style="text-align: center;">
                <div class="subtitle">ICCV 2023 Tutorial on</div>
                <h1>Learning with Noisy and Unlabeled Data for Large Models beyond Categorization</h1>
                <div class="subtitle" style="color: #ccc; margin: 20px">
                  Oct 3 Full-day, ICCV 2023 Tutorial (Hybrid)
                </div>
                <div class="subtitle" style="color: rgb(0, 0, 0); margin: 20px">
                </div>
                <div class="subtitle" style="color: #ccc; margin: 20px">
                  <a href=""> Full recording of our tutorial.</a>
                </div>
                <div class="subtitle" style="color: #ccc; margin: 20px">
                  <b> <font color=red> Attend our tutorial <a href=""> here</a> </font> </b> (virtual) and @room P02 (in person).
                </div>
            </div>
        </div>

        <div class="container">
            <div class="section" id="intro">
                <h2>Overview</h2>

                <p>
                  How to train glowingly larger vision deep neural networks, i.e., learning representations for images, videos and 3D textured shapes, when there is insufficient labelled data or noisy data? This is a persistent and increasingly urgent challenge amid the rapid development of large-scale vision models.
                  In this tutorial, we will explore a collection of recent research works that address this challenge. These works cover a range of topics, including self-, weakly-, and text-supervised learning, zero-shot learning, test-time adaptation, and data-efficient training approaches. By discussing these approaches, we aim to provide a comprehensive overview of the latest techniques and advancements in the field of training large-scale vision models with limited labeled data. 
                </p>

                <!-- <p>
                  In recent years, the demand for large-scale models has grown significantly, requiring large-scale annotated data to effectively train them. However, annotating such data, particularly for tasks like pixel-level classification in large-scale video datasets, image or 3D shape editing, can be either resource-intensive, or unobtainable. Unsupervised learning approaches have shown promising results for training image classification networks without labeled data, but challenges remain in learning beyond categorization. Further research is necessary to facilitate the effective training of large-scale models with limited annotated data across a range of divergent vision tasks and deployment scenarios. 
                  <ul>
                    <li>For vision tasks different from categorization</li>
                    <li>For applications requiring efficient generalization</li>
                    <li>For the data not shareable </li>
                    <li>...</li>
                  </ul> -->
                  In detail, our talks will cover and discussions on the following topics: 
                  <ul>
                    <li>self-supervised representation learning for images and videos in the 2D domain</li>
                    <li>zero- and one-shot learning</li>
                    <li>Open-Vocabulary representation learning </li>
                    <li>test-time and data-efficient training approaches</li>
                    <li>data-free learning</li>
                  </ul>
                   Challenges from specific application domain such as autonomous vehicles will be thoroughly discussed.
                </p>

                <!-- <p>
                  In affiliation to this workshop, we are also organizing the <a href="https://sapien.ucsd.edu/challenges/maniskill2021/">ManiSkill Challenge</a>, which focuses on learning to manipulate unseen objects in simulation with 3D visual inputs. We will announce winners and host winner presentations in this workshop.
                </p> -->

            </div>


            <div class="section" id="schedule">
                <h2>Tutorial Schedule</h2>
                Please attend our tutorial via our <a href="https://iccv2023.thecvf.com/list.of.accepted.tutorials-91.php"> ICCV tutorial website</a>. Slides and videos will be released right after the tutorial.
                <ul></ul>
                    <!-- <table style="width: 100%">
                      <tr> <th>Start</th> <th>End</th> <th>Event</th> </tr>
                      <tr><td>8:20am</td><td>9:00am</td><td>Opening Remark</td></tr>
                      <tr><td>9:00am</td><td>9:30am</td><td>Keynote speaker</td></tr>
                      <tr><td>9:30am</td><td>10:00am</td><td>Keynote speaker</td></tr>
                      <tr><td>10:00am</td><td>10:40am</td>
                      <td>Spottrght Section: Simulation Environments for Embodied AI</td></tr>
                      <tr><td>10:40am</td><td>11:10am</td><td>Keynote speaker</td></tr>
                      <tr><td>11:10am</td><td>11:40am</td><td>Keynote speaker</td></tr>
                      <tr><td>11:40am</td><td>12:10pm</td><td>Keynote speaker</td></tr>
                      <tr><td>12:10pm</td><td>1:30pm</td><td>Lunch</td></tr>
                      <tr><td>1:30pm</td><td>2:00pm</td><td>Keynote speaker</td></tr>
                      <tr><td>2:00pm</td><td>2:30pm</td><td>Keynote speaker</td></tr>
                      <tr><td>2:30pm</td><td>3:00pm</td><td>Keynote speaker</td></tr>
                      <tr><td>3:00pm</td><td>3:40pm</td><td>Accepted Paper Spottrght Presentation</td></tr>
                      <tr><td>3:40pm</td><td>4:10pm</td><td>Keynote speaker</td></tr>
                      <tr><td>4:10pm</td><td>4:40pm</td><td>Keynote speaker</td></tr>
                      <tr><td>4:40pm</td><td>5:10pm</td><td>Panel Discussion and Community Building</td></tr>
                    </table> -->
                    <style type="text/css">
                      /* .tg  {border-collapse:collapse;border-spacing:0;}
                      .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
                        overflow:hidden;padding:10px 5px;word-break:normal;}
                      .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
                        font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} */
                      .tg .tg-u4qn{background-color:#D9D9D9;text-align:left;vertical-align:bottom}
                      /* .tg .tg-7zrl{text-align:left;vertical-align:bottom} */
                    </style>
                    <table class="tg">
                      <thead>
                        <tr>
                          <th class="tg-u4qn"><span style="background-color:#D9D9D9">Start Time (PDT)</span></th>
                          <th class="tg-u4qn"><span style="background-color:#D9D9D9">End Time (PDT)</span></th>
                          <th class="tg-u4qn"><span style="background-color:#D9D9D9">Event</span></th>
                        </tr>
                      </thead>
                      <tbody>
                        <tr>
                          <td class="tg-jkyp">8:20:00 AM</td>
                          <td class="tg-jkyp">8:30:00 AM</td>
                          <td class="tg-za14">Intro and Opening Remark</td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">8:30:00 AM</td>
                          <td class="tg-jkyp">9:10:00 AM</td>
                          <td class="tg-za14">Invited Talk (Shalini De Mello): Open-Vocabulary Recognition with Large Image-Text Foundational Models </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">9:10:00 AM</td>
                          <td class="tg-jkyp">9:50:00 AM</td>
                          <td class="tg-za14">Invited Talk (Xin Wang): Data-Efficient Learning via Top-Down Attention Steering
                          </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">9:50:00 AM</td>
                          <td class="tg-jkyp">10:00:00 AM</td>
                          <td class="tg-za14">Break</td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">10:00:00 AM</td>
                          <td class="tg-jkyp">10:40:00 AM</td>
                          <td class="tg-za14">Invited Talk (Varun Jampani): 3D of Everything: Automatic 3D Object Understanding from Internet Image Collections
                          </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">10:40:00 AM</td>
                          <td class="tg-jkyp">11:20:00 AM</td>
                          <td class="tg-za14">Invited Talk (Xueting Li): Zero-/One-shot learning for deformable 3D avatars </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">11:20:00 AM</td>
                          <td class="tg-jkyp">12:00:00 AM</td>
                          <td class="tg-za14">Invited Talk (Xinlei Chen): Self-supervised learning: two known paradigms and a less-known observation </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">12:00:00 AM</td>
                          <td class="tg-jkyp">1:30:00 PM</td>
                          <td class="tg-za14">Lunch Break</td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">1:30:00 PM</td>
                          <td class="tg-jkyp">1:40:00 PM</td>
                          <td class="tg-za14">Opening Remarks on Data-efficienty Learning </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">1:40:00 PM</td>
                          <td class="tg-jkyp">2:20:00 PM</td>
                          <td class="tg-za14">Invited Talk (Ishan Misra): Using unlabeled data to scale representations across modalities </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">2:20:00 PM</td>
                          <td class="tg-jkyp">3:00:00 PM</td>
                          <td class="tg-za14">Invited Talk (Pavlo Molchanov): Data-efficient post-training optimization for large models </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">3:00:00 PM</td>
                          <td class="tg-jkyp">3:10:00 PM</td>
                          <td class="tg-za14">Break</td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">3:10:00 PM</td>
                          <td class="tg-jkyp">3:50:00 PM</td>
                          <td class="tg-za14">Invited Talk (Bichen Wu): Data-efficient language-supervised zero-shot visual learning with self-distillation </td>
                        </tr>
                        <tr>
                          <td class="tg-jkyp">3:50:00 PM</td>
                          <td class="tg-jkyp">4:20:00 PM</td>
                          <td class="tg-za14">Invited Talk (Rafid Mahmood): Optimizing Data Collection for Machine Learning </td>
                        </tr>
                          <td class="tg-jkyp">4:20:00 PM</td>
                          <td class="tg-jkyp">4:30:00 PM</td>
                          <td class="tg-za14">Closing Remarks</td>
                        </tr>
                      </tbody>
                    </table>
                <ul>
                </ul>
            </div>

            <div class="section" id="speakers">
                <h2>Invited Speakers</h2>
                <!-- <p> listed alphabetically </p> -->
                <div class="people">
                  <a href="https://research.nvidia.com/person/shalini-de-mello">
                    <img src="assets/Shalini-De-Mello.jpeg">
                    <div>Shalini De Mello</div>
                    <div class="aff">NVIDIA</div>
                  </a>
                  <a href="https://xinw.aixin/">
                    <img src="assets/xin_wang.jpeg">
                    <div>Xin Wang</div>
                    <div class="aff">Microsoft Research</div>
                  </a>
                  <a href="https://varunjampani.github.io/">
                    <img src="assets/varun.jpeg">
                    <div>Varun Jampanivarun</div>
                    <div class="aff">Google Research</div>
                  </a>
                  <a href="https://sunshineatnoon.github.io/">
                    <img src="assets/xt.jpeg">
                    <div>Xueting Li</div>
                    <div class="aff">NVIDIA</div>
                  </a>
                  <a href="https://yueatsprograms.github.io/">
                    <img src="assets/xinlei.jpeg">
                    <div>Xinlei Chen</div>
                    <div class="aff">Meta AI</div>
                  </a>
                  <a href="https://imisra.github.io/">
                    <img src="assets/ishan.jpeg">
                    <div>Ishan Misra</div>
                    <div class="aff">Meta</div>
                  </a>
                  <a href="https://www.pmolchanov.com/">
                    <img src="assets/pavlo.png">
                    <div>Pavlo Molchanov</div>
                    <div class="aff">NVIDIA</div>
                  </a>
                  <a href="https://scholar.google.com/citations?user=K3QJPdMAAAAJ&hl=en">
                    <img src="assets/bichen.jpeg">
                    <div>Bichen Wu</div>
                    <div class="aff">Meta Reality Labs</div>
                  </a>
                  <a href="https://rafidrm.github.io/">
                    <img src="assets/RMahmood_V2.jpeg">
                    <div>Rafid Mahmood</div>
                    <div class="aff">University of Ottawa</div>
                  </a>
                </div>
                <div class="people">
                </div>
            </div>

            <div class="section" id="organizers">
              <h2>Organizers</h2>
              <!-- <p> listed alphabetically </p> -->
              <div class="people">
                <a href="https://sifeiliu.net/">
                  <img src="assets/sifei-liu.jpeg">
                  <div>Sifei Liu</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://hongxu-yin.github.io/">
                  <img src="assets/danny_yin.png">
                  <div>HongXu (Danny) Yin</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://research.nvidia.com/person/shalini-de-mello">
                  <img src="assets/Shalini-De-Mello.jpeg">
                  <div>Shalini De Mello</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://www.pmolchanov.com/">
                  <img src="assets/pavlo.png">
                  <div>Pavlo Molchanov</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://alvarezlopezjosem.github.io/">
                  <img src="assets/jose_alvarez_4.jpg">
                  <div>Jose M. Alvarez</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://jankautz.com/">
                  <img src="assets/jan.jpeg">
                  <div>Jan Kautz</div>
                  <div class="aff">NVIDIA</div>
                </a>
                <a href="https://xiaolonw.github.io/">
                  <img src="assets/xiaolong.jpeg">
                  <div>Xiaolong Wang</div>
                  <div class="aff">UC San Diego</div>
                </a>
                <a href="http://tensorlab.cms.caltech.edu/users/anima/">
                  <img src="assets/Anima-Anandkumar.jpg">
                  <div>Anima Anandkumar</div>
                  <div class="aff">Caltech & NVIDIA</div>
                </a>
                <a href="http://faculty.ucmerced.edu/mhyang/">
                  <img src="assets/mhyang2005_70.jpg">
                  <div>Ming-Hsuan Yang</div>
                  <div class="aff">UC Merced</div>
                </a>
                <a href="http://people.eecs.berkeley.edu/~trevor/">
                  <img src="assets/trevor.jpeg">
                  <div>Trevor Darrell</div>
                  <div class="aff">UC Berkeley</div>
                </a>
              </div>
            </div>

            <div class="section" id="contact">
                <h2>Contact</h2>
                <div>For any questions, you may contact us at <a href="mailto:sifeil@nvidia.com">sifeil@nvidia.com</a> or <a href="mailto:dannyy@nvidia.com">dannyy@nvidia.com</a></div>
            </div>

        </div>
        <div class="foot">
          © 2023 Learning with Noisy and Unlabeled Data for Large Models beyond Categorization
        </div>
    </body>
</html>
